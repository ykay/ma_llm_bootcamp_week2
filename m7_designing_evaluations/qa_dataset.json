[{"question": "What was the main topic of the class?", "expected_output": "To learn the basic building blocks of creating an LLM app."}, {"question": "What was surprising about LLMs mentioned in the class?", "expected_output": "LLMs are stateless and require the entire chat history for each new message."}, {"question": "How does LLM performance degrade under load?", "expected_output": "As more requests are made, the tokens per second rate decreases in a linear way."}, {"question": "What are the two aspects of LLMs discussed?", "expected_output": "Inference and the web server that surrounds it."}, {"question": "What is the significance of temperature in LLMs?", "expected_output": "Temperature affects the randomness of responses and should be tuned for different solutions."}, {"question": "Who are the major providers of LLM APIs mentioned?", "expected_output": "OpenAI and Anthropic."}, {"question": "What is the cost implication of using dedicated GPUs?", "expected_output": "Dedicated GPUs are very expensive to rent, especially for fine-tuning models."}, {"question": "What is the purpose of the evaluation system in AI solutions?", "expected_output": "To ensure that AI solutions meet a certain satisfaction rate, ideally above 80%."}, {"question": "What is the difference between a Capstone project and weekly projects?", "expected_output": "Capstone projects can be individual or group projects, while weekly projects are more structured."}, {"question": "What is the first goal of the class?", "expected_output": "To familiarize students with AI vocabulary and concepts."}, {"question": "What is RAG in the context of LLMs?", "expected_output": "Retrieval Augmented Generation, a technique to enhance LLM responses by retrieving relevant context."}, {"question": "What is the importance of prompt design in LLMs?", "expected_output": "Prompt design significantly influences the behavior and output of LLMs."}, {"question": "What is the expected outcome of fine-tuning an LLM?", "expected_output": "To improve the fidelity of the model and reduce costs."}, {"question": "What is the role of the 'traceable' function in the lab?", "expected_output": "To allow tracking of all calls made to the LLM for better debugging and understanding."}, {"question": "What is the significance of the 'prompt compliance' metric?", "expected_output": "It evaluates how well the LLM adheres to the instructions given in the prompt."}, {"question": "What is the structure of the evaluation system discussed in the class?", "expected_output": "It consists of a dataset of interactions, an evaluator, and a scoring system."}, {"question": "What is the expected output of the evaluation process?", "expected_output": "A score and reasoning for the compliance of the LLM's response."}, {"question": "What is the purpose of the weekly project due Sunday at midnight?", "expected_output": "To practice building LLM apps and applying the concepts learned in class."}, {"question": "What is the main challenge when bringing AI solutions to production?", "expected_output": "Achieving a satisfaction rate above 80% is extraordinarily hard."}, {"question": "What is the expected interaction between the student and the AI tutor?", "expected_output": "The AI tutor should provide real-time assessments and support based on the student's progress."}]